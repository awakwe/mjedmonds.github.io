<!DOCTYPE html>
<!--[if lt IE 8 ]><html class="no-js ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="no-js ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 8)|!(IE)]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>

  <!--- Basic Page Needs
    ================================================== -->
  <meta charset="utf-8">
  <title>A tale of two explanations: Enhancing human trust by explaining robot behavior<</title> <meta name="description" content="A tale of two explanations: Enhancing human trust by explaining robot behavior<">
      <meta name="author" content="Mark Edmonds">

      <!-- Mobile Specific Metas
      ================================================== -->
      <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

      <!-- Google analytics -->
      <script>
        (function(i, s, o, g, r, a, m)
        {
          i['GoogleAnalyticsObject'] = r;
          i[r] = i[r] || function()
          {
            (i[r].q = i[r].q || []).push(arguments)
          }, i[r].l = 1 * new Date();
          a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
          a.async = 1;
          a.src = g;
          m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-98378227-1', 'auto');
        ga('send', 'pageview');
      </script>

      <!-- CSS
        ================================================== -->
      <link rel="stylesheet" href="../../css/default.css">
      <link rel="stylesheet" href="../../css/teaching-layout.css">
      <link rel="stylesheet" href="../../css/media-queries.css">
      <link rel="stylesheet" href="../../css/mjedmonds.css">
      <link rel="stylesheet" href="../../css/magnific-popup.css">
      <link rel="stylesheet" href="../../highlight/styles/default.css">

      <!-- Script
          ================================================== -->
      <script src="../../js/modernizr.js"></script>
      <script src="../../js/smooth-scroll.js"></script>

      <!--code hightlighting-->
      <script src="../../highlight/highlight.pack.js"></script>

      <!-- Favicons
            ================================================== -->
      <link rel="shortcut icon" href="../../favicon.png">

</head>

<body>

  <!-- Header
                ================================================== -->
  <header id="home">

    <nav id="nav-wrap">

      <a class="mobile-btn" href="#nav-wrap" title="Show navigation">Show navigation</a>
      <a class="mobile-btn" href="#" title="Hide navigation">Hide navigation</a>

      <ul id="nav" class="nav">
        <li><a href="../../index.html">Home</a></li>
      </ul>
      <!-- end #nav -->

    </nav>
    <!-- end #nav-wrap -->

  </header>
  <!-- Header End -->

  <section class="project-page-section">

    <div class="wide-row project-page">

      <div class="three columns header-col">
        <h1><span>Abstract</span></h1>
      </div>

      <div class="nine columns main-col">

        <div class="wide-row item">

          <div class="twelve columns">

            <h2>A tale of two explanations: Enhancing human trust by explaining robot behavior</h2>
            <p>
              Mark Edmonds<sup>1</sup>, Feng Gao<sup>2</sup>, Hangxin Liu<sup>1</sup>, Xu Xie<sup>2</sup>, Siyuan Qi<sup>1</sup>, Brandon Rothrock <sup>3</sup>, Yixin Zhu<sup>2</sup>, Ying Nian Wu <sup>2</sup>, Hongjing Lu<sup>2,4</sup>, Song-Chun Zhu<sup>1,2</sup>
              <br>
              <small>
                1 Department of Computer Science, UCLA | 2 Department of Statistics, UCLA | 3 Jet Propulsion Lab, Caltech | 4 Department of Pyschology, UCLA
              </small>
            </p>
            <h5>Abstract</h5>
            <p>
              The ability to provide comprehensive explanations of chosen actions is a hallmark of intelligence. Lack of this ability impedes the general acceptance of AI and robot systems in critical tasks. This paper examines what forms of explanations best foster human trust in machines and proposes a framework in which explanations are generated from both functional and mechanistic perspectives. The robot system learns from human demonstrations to open medicine bottles using (i) an embodied haptic prediction model to extract knowledge from sensory feedback, (ii) a stochastic grammar model induced to capture the compositional structure of a multistep task, and (iii) an improved Earley parsing algorithm to jointly leverage both the haptic and grammar models. The robot system not only shows the ability to learn from human demonstrators but also succeeds in opening new, unseen bottles. Using different forms of explanations generated by the robot system, we conducted a psychological experiment to examine what forms of explanations best foster human trust in the robot. We found that comprehensive and real-time visualizations of the robot’s internal decisions were more effective in promoting human trust than explanations based on summary text descriptions. In addition, forms of explanation that are best suited to foster trust do not necessarily correspond to the model components contributing to the best task performance. This divergence shows a need for the robotics community to integrate model components to enhance both task execution and human trust in machines.
            </p>
            <div class="columns download">
              <a href="http://robotics.sciencemag.org/cgi/content/full/4/37/eaay4663?ijkey=fn9h.cykmWa7.&keytype=ref&siteid=robotics" class="button"><i class="fa fa-download"></i>Download Paper</a>
              <a href="https://robotics.sciencemag.org/content/suppl/2019/12/16/4.37.eaay4663.DC1" class="button"><i class="fa fa-download"></i>Download Supplementary</a>
            </div>
          </div>

        </div>

      </div>
      <!-- main-col end -->

    </div>
  </section>

  <section class="project-page-section">

    <div class="wide-row project-page">

      <div class="three columns header-col">
        <h1><span>Selected Figures</span></h1>
      </div>

      <div class="nine columns main-col">

        <div class="wide-row item">

          <div class="twelve columns">

            <div style="margin: 0 auto;">
              <figure style=>
                <img class="centerimg" style="width: 80%; padding: 2%" src="./system-arch_v3.png" alt="System architecture">
                <figcaption>Fig. 1 Overview of demonstration, learning, evaluation, and explainability. By observing human demonstrations, the robot learns, performs, and explains using both a symbolic representation and a haptic representation. (A) Fine-grained human manipulation data were collected using a tactile glove. On the basis of the human demonstrations, the model learns (B) symbolic representations by inducing a grammar model that encodes long-term task structure to generate mechanistic explanations and (C) embodied haptic representations using an autoencoder to bridge the human and robot sensory input in a common space, providing a functional explanation of robot action. These two components are integrated using (D) the GEP for action planning. These processes complement each other in both (E) improving robot performance and (F) generating effective explanations that foster human trust.</figcaption>
              </figure>
            </div>
            <div style="margin: 0 auto;">
              <figure>
                <img class="centerimg" style="width: 80%; padding: 1%" src="./panels-over-time-combined-v3.png" alt="explanation panels over time">
                <figcaption>Fig. 5 Explanations generated by the symbolic planner and the haptic model. (A) Symbolic (mechanistic) and haptic (functional) explanations at a0 of the robot action sequence. (B to D) Explanations at times a2, a8, and a9, respectively, where ai refers to the ith action. Note that the red on the robot gripper’s palm indicates a large magnitude of force applied by the gripper, and green indicates no force; other values are interpolated. These explanations are provided in real time as the robot executes.</figcaption>
              </figure>
            </div>

          </div>

        </div>

      </div>
      <!-- main-col end -->

    </div>
  </section>

  <section class="project-page-section">

    <div class="wide-row project-page">

      <div class="three columns header-col">
        <h1><span>Videos</span></h1>
      </div>

      <div class="nine columns main-col">

        <div class="wide-row item">

          <div class="twelve columns">

            <div style="padding:58.02% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/380861069" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe></div>
            <script src="https://player.vimeo.com/api/player.js"></script>
            <p><a href="https://vimeo.com/380861069">A tale of two explanations: Enhancing human trust by explaining robot behavior - Summary</a> from <a href="https://vimeo.com/user69261739">Mark Edmonds</a> on <a href="https://vimeo.com">Vimeo</a>.</p>

          </div>

        </div>

      </div>
      <!-- main-col end -->

    </div>
  </section>

  <section class="project-page-section">

    <div class="wide-row project-page">

      <div class="three columns header-col">
        <h1><span>Bibtex</span></h1>
      </div>

      <div class="nine columns main-col">

        <div class="wide-row item">
          <pre><code class="no-highlight hljs">@article{edmonds2019tale,
  title={A tale of two explanations: Enhancing human trust by explaining robot behavior<},
  author={Edmonds, Mark and Gao, Feng and Liu, Hangxin and Xie, Xu and Qi, Siyuan and Rothrock, Brandon and and Zhu, Yixin and Wu, Ying Nian and Lu, Hongjing and Zhu, Song-Chun},
  journal={Science Robotics},
  volume={4},
  number={37},
  pages={eaay4663},
  year={2019},
  publisher={AAAS}
}</code></pre>

        </div>

      </div>
      <!-- main-col end -->

    </div>
  </section>

  <section class="project-page-section">

    <div class="wide-row project-page">

      <div class="three columns header-col">
        <h1><span>News Coverage</span></h1>
      </div>

      <div class="nine columns main-col">

        <div class="wide-row item">
          <ul>
            <li>
              IEEE Spectrum: <a href="https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/a-robot-that-explains-its-actions">A Robot That Explains Its Actions Is a First Step Towards AI We Can (Maybe) Trust</a>
            </li>
            <li>
              UCLA Samueli School of Engineering: <a href="https://samueli.ucla.edu/in-robots-we-trust-ucla-study-shows-way-forward/">In Robots We Trust? UCLA Study Shows Way Forward</a>
            </li>
            <li>
              Tech Xplore: <a href="https://techxplore.com/news/2019-12-robot-people-robots.html">Robot experiment shows people trust robots more when robots explain what they are doing</a>
            </li>
          </ul>
        </div>

      </div>
      <!-- main-col end -->

    </div>
  </section>

  <!-- footer ================================================== -->
  <footer>

    <div class="row">

      <div class="twelve columns">

        <ul class="copyright">
          <li>&copy; Copyright 2014 CeeVee</li>
          <li>Design by <a title="Styleshout" href="http://www.styleshout.com/">Styleshout</a></li>
        </ul>

      </div>

      <div id="go-top"><a data-scroll data-options='{"offset": 0}' title="Back to Top" href="#home"><i class="icon-up-open"></i></a></div>

    </div>

  </footer>
  <!-- Footer End-->


  <!-- Java Script ================================================== -->
  <script>
    hljs.initHighlightingOnLoad();
  </script>
  <script>
    smoothScroll.init();
  </script>
</body>

</html>